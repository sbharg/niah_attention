{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52301d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m97 packages\u001b[0m \u001b[2min 0.37ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m78 packages\u001b[0m \u001b[2min 0.02ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install transformers datasets tiktoken matplotlib pandas seaborn torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa4ec95",
   "metadata": {},
   "source": [
    "#### config.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c69d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    output_attentions=True,\n",
    "    attn_implementation=\"eager\",\n",
    "    return_dict_in_generate=True,\n",
    ").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b294605",
   "metadata": {},
   "source": [
    "#### mrcr_utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ab4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbharg/homework/ut_austin/cs391l_machine_learning/niah_attention/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def load_mrcr_parquet():\n",
    "    df = pd.read_parquet(\n",
    "        hf_hub_download(\n",
    "            repo_id=\"openai/mrcr\", filename=\"2needle.parquet\", repo_type=\"dataset\"\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_messages(prompt_str):\n",
    "    return json.loads(prompt_str)\n",
    "\n",
    "\n",
    "def grade(response, answer, random_string_to_prepend) -> float:\n",
    "    if not response.startswith(random_string_to_prepend):\n",
    "        return 0\n",
    "    response = response.removeprefix(random_string_to_prepend)\n",
    "    answer = answer.removeprefix(random_string_to_prepend)\n",
    "    return float(SequenceMatcher(None, response, answer).ratio())\n",
    "\n",
    "\n",
    "def n_tokens(messages: list[dict]) -> int:\n",
    "    \"\"\"\n",
    "    Count tokens in messages.\n",
    "    \"\"\"\n",
    "    return sum([len(tokenizer([m])) for m in messages])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684e88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_mrcr_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dataset.iterrows():\n",
    "    messages = json.loads(row[\"prompt\"])\n",
    "    if n_tokens(messages) > 10000:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    output_attentions=True,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(inputs.input_ids, output.sequences)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attention = output.attentions\n",
    "# attention_matrix_l1 = attention[0][0][0].cpu().float().numpy()\n",
    "\n",
    "# sns.heatmap(attention_matrix_l1[0], xticklabels=tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]),\n",
    "#             yticklabels=tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]), cmap=\"viridis\")\n",
    "# plt.title(\"Attention Weights\")\n",
    "# plt.show()\n",
    "\n",
    "cmap = sns.color_palette(\"blend:#7AB,#EDA\", as_cmap=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 7, figsize=(50, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sns.heatmap(\n",
    "        attention[0][0][0][i].cpu().float().numpy(),\n",
    "        ax=ax,\n",
    "        cmap=\"bone\",\n",
    "        xticklabels=tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]),\n",
    "        yticklabels=tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]),\n",
    "    )\n",
    "    ax.set_title(f\"Head {i + 1}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
